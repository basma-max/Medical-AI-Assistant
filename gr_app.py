
# import os
# import base64
# import gradio as gr
# from brain_doctor import analyser_image 
# from voice_patient import transcribe_with_groq
# from voice_doctor import VoiceAssistant

# # Configuration initiale
# voice_doctor = VoiceAssistant()

# SYSTEM_PROMPT = """En tant que sp√©cialiste m√©dical, analysez cette image en :
# 1. Identifiant 1-2 pathologies potentielles
# 2. Recommandant des actions appropri√©es
# 3. Indiquant l'urgence de consultation
# R√©pondez en fran√ßais, clairement et avec bienveillance (max 3 phrases)."""

# def encode_image(image_path):
#     """Encode l'image en base64 de mani√®re optimis√©e"""
#     with open(image_path, "rb") as f:
#         return base64.b64encode(f.read()).decode('utf-8')


# def process_medical_request(audio_filepath, image_filepath):
#     try:
#         # 1. Transcription vocale
#         speech_text = transcribe_with_groq(
#         audio_filepath=audio_filepath,
#         GROQ_API_KEY=os.getenv("GROQ_API_KEY"),
#         stt_model="whisper-large-v3"
#         ) if audio_filepath else ""

#         # 2. Analyse m√©dicale
#         if image_filepath:
#             # prompt = f"{SYSTEM_PROMPT}\n\nPatient: {speech_text}" if speech_text else SYSTEM_PROMPT
#             doctor_response = analyser_image(image_filepath+speech_text)
#         else:
#             doctor_response = "Veuillez fournir une image pour une analyse pr√©cise."

#         # 3. Synth√®se vocale
#         if os.getenv("ELEVENLABS_API_KEY"):
#             audio_file = voice_doctor.text_to_speech_with_elevenlabs(
#             text=doctor_response,
#             output_file="response.mp3"  # Bon nom de param√®tre
#              )
#         else:
#             audio_file = voice_doctor.text_to_speech_with_gtts(
#                 text=doctor_response,
#                 output_filepath="response.mp3",
#                 lang='fr'
#             )

#         return speech_text, doctor_response, audio_file

#     except Exception as e:
#         error = f"Erreur syst√®me : {str(e)}"
#         return error, error, None

# # Interface Gradio optimis√©e
# with gr.Blocks(theme=gr.themes.Soft(), title="Assistant M√©dical IA") as app:
#     gr.Markdown("""
#     # ü©∫ Diagnostic M√©dical Assist√©
#     *Analyse pr√©liminaire d'images m√©dicales avec IA*
#     """)
    
#     with gr.Row():
#         with gr.Column():
#             audio_input = gr.Audio(
#                 sources=["microphone"],
#                 type="filepath",
#                 label="D√©crivez vos sympt√¥mes"
#             )
#             image_input = gr.Image(
#                 type="filepath",
#                 label="Image M√©dicale"
#             )
#             submit_btn = gr.Button("Analyser", variant="primary")
        
#         with gr.Column():
#             transcription = gr.Textbox(label="Transcription")
#             diagnosis = gr.Textbox(label="Diagnostic Pr√©liminaire")
#             voice_output = gr.Audio(
#                 label="R√©ponse Vocale",
#                 autoplay=True,
#                 interactive=False
#             )
    
#     submit_btn.click(
#         fn=process_medical_request,
#         inputs=[audio_input, image_input],
#         outputs=[transcription, diagnosis, voice_output]
#     )

# if __name__ == "__main__":
#     # Validation des cl√©s API
#     if not os.getenv("GROQ_API_KEY"):
#         raise ValueError("Cl√© GROQ_API_KEY manquante dans .env")
    
#     app.launch(
#         server_name="0.0.0.0",
#         server_port=7860,
#         show_error=True,
#         share=False  # True pour un lien public
#     )


import os
import base64
import gradio as gr
from brain_doctor import analyser_image 
from voice_patient import transcribe_with_groq
from voice_doctor import VoiceAssistant

# Configuration initiale
voice_doctor = VoiceAssistant()

SYSTEM_PROMPT = """En tant que sp√©cialiste m√©dical, analysez cette image en :
1. Identifiant 1-2 pathologies potentielles
2. Recommandant des actions appropri√©es
3. Indiquant l'urgence de consultation
R√©pondez en fran√ßais, clairement et avec bienveillance (max 3 phrases)."""

def encode_image(image_path):
    """Encode l'image en base64 de mani√®re optimis√©e"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')


def process_medical_request(audio_filepath, image_filepath):
    try:
        # 1. Transcription vocale
        speech_text = transcribe_with_groq(
            audio_filepath=audio_filepath
            # GROQ_API_KEY=os.getenv("GROQ_API_KEY"),
            # stt_model="whisper-large-v3"
        ) if audio_filepath else ""

        # 2. Analyse m√©dicale
        if image_filepath:
            # Important : ne pas concat√©ner chemin + texte
            # On envoie ici uniquement le chemin d'image, ou encode l'image si n√©cessaire
            # Si analyser_image accepte un param√®tre "contexte" avec la transcription, il faudrait l‚Äôajouter
            # Exemple (si ta fonction supporte) :
            # doctor_response = analyser_image(image_path=image_filepath, context_text=speech_text)

            # Sinon, en l'√©tat, on envoie juste l'image
            doctor_response = analyser_image(image_filepath)
            
            # Optionnel : tu peux pr√©fixer le prompt syst√®me + transcription dans ta fonction analyser_image si tu veux
        else:
            doctor_response = "Veuillez fournir une image pour une analyse pr√©cise."

        # 3. Synth√®se vocale
        if os.getenv("ELEVENLABS_API_KEY"):
            audio_file = voice_doctor.text_to_speech_with_elevenlabs(
                text=doctor_response,
                output_file="response.mp3"  # V√©rifie bien que c‚Äôest le nom attendu par ta fonction
            )
        else:
            audio_file = voice_doctor.text_to_speech_with_gtts(
                text=doctor_response,
                output_filepath="response.mp3",  # V√©rifie si c‚Äôest output_filepath ou output_file selon ta fonction
                lang='fr'
            )

        # On retourne le chemin du fichier audio pour Gradio
        return speech_text, doctor_response, "response.mp3"

    except Exception as e:
        error = f"Erreur syst√®me : {str(e)}"
        return error, error, None

# Interface Gradio optimis√©e
with gr.Blocks(theme=gr.themes.Soft(), title="Assistant M√©dical IA") as app:
    gr.Markdown("""
    # ü©∫ Diagnostic M√©dical Assist√©
    *Analyse pr√©liminaire d'images m√©dicales avec IA*
    """)

    with gr.Row():
        with gr.Column():
            audio_input = gr.Audio(
                sources=["microphone"],
                type="filepath",
                label="D√©crivez vos sympt√¥mes"
            )
            image_input = gr.Image(
                type="filepath",
                label="Image M√©dicale"
            )
            submit_btn = gr.Button("Analyser", variant="primary")

        with gr.Column():
            transcription = gr.Textbox(label="Transcription")
            diagnosis = gr.Textbox(label="Diagnostic Pr√©liminaire")
            voice_output = gr.Audio(
                label="R√©ponse Vocale",
                type="filepath",  # Important pour lire un fichier g√©n√©r√© dynamiquement
                autoplay=True,
                interactive=False
            )

    submit_btn.click(
        fn=process_medical_request,
        inputs=[audio_input, image_input],
        outputs=[transcription, diagnosis, voice_output]
    )

if __name__ == "__main__":
    # Validation des cl√©s API
    if not os.getenv("GROQ_API_KEY"):
        raise ValueError("Cl√© GROQ_API_KEY manquante dans .env")

    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        share=False  # True pour un lien public
    )
